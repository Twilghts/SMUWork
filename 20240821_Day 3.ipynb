{"cells":[{"cell_type":"markdown","id":"70086f1a","metadata":{"id":"70086f1a"},"source":["### 20240822_Day 3"]},{"cell_type":"code","execution_count":null,"id":"fiVWz8nBg_X6","metadata":{"id":"fiVWz8nBg_X6"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.optim import lr_scheduler\n","from torchvision.models import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights\n","from datetime import datetime\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"code","source":["model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","\n","for name, param in model.named_parameters():\n","    print(name, param.shape)"],"metadata":{"collapsed":true,"id":"njnSflxuQ-tM"},"id":"njnSflxuQ-tM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_layer_name, last_layer = list(model.named_modules())[-1]\n","featveclen = last_layer.weight.shape[1]\n","n_class = 10\n","exec(\"model.%s = nn.Linear(%s,%s)\" %\n","    (last_layer_name, featveclen, n_class)\n",")\n","\n","for name, param in model.named_parameters():\n","    print(name, param.shape)"],"metadata":{"id":"MOT30u8xQ-46"},"id":"MOT30u8xQ-46","execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Exact same code as Day 2 ###\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","root = \".\"\n","\n","class DataManager:\n","    def __init__(self):\n","        self.C, self.H, self.W = 3, 32, 32\n","        self.batch_size = 64\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","        self.trainset = torchvision.datasets.CIFAR10(\n","            root=root, train=True,\n","            download=True, transform=self.transform\n","        )\n","        self.testset = torchvision.datasets.CIFAR10(\n","            root=root, train=False,\n","            download=True, transform=self.transform\n","        )\n","        self.class_to_idx = self.trainset.class_to_idx\n","        self.classes = list(self.class_to_idx.keys())\n","\n","        self.trainloader = torch.utils.data.DataLoader(\n","            self.trainset, batch_size=self.batch_size,\n","            shuffle=True, num_workers=0\n","        )\n","        self.testloader = torch.utils.data.DataLoader(\n","            self.testset, batch_size=self.batch_size,\n","            shuffle=False, num_workers=0\n","        )"],"metadata":{"id":"3CHLYhFBM8X4"},"id":"3CHLYhFBM8X4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Almost the code as Day 2; just BasicNet replaced with resnet18 ###\n","class Classifier:\n","    def __init__(self, dataMananger):\n","        self.dataMananger = dataMananger\n","        self.trainloader = self.dataMananger.trainloader\n","        self.testloader = self.dataMananger.testloader\n","        self.classes = self.dataMananger.classes\n","        self.device = torch.device(\n","            torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n","        )\n","        print(\"Using device %s\" % self.device)\n","\n","        input_shape = (self.dataMananger.C, self.dataMananger.H, self.dataMananger.W)\n","        # self.model = BasicNet(\n","        #     input_shape, num_classes=len(self.classes)\n","        # )\n","        ### Replace with this ###\n","        self.model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","\n","        last_layer_name, last_layer = list(self.model.named_modules())[-1]\n","        featveclen = last_layer.weight.shape[1]\n","        n_class = len(self.classes)\n","        exec(\"self.model.%s = nn.Linear(%s,%s)\" % \\\n","            (last_layer_name, featveclen, n_class)\n","        )\n","        #########################\n","        self.model.to(self.device)\n","        self.loss_function = nn.CrossEntropyLoss()\n","\n","\n","    def train(self, epochs=1, lr=1e-3, save=True, overfit=False):\n","        self.lr = lr\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n","\n","        print(\"Beginning training for %d epochs\" % epochs)\n","        self.model.train()\n","        for epoch in range(epochs):\n","            for i, data in enumerate(self.trainloader):\n","                images, y_true = data\n","                images, y_true = images.to(self.device), y_true.to(self.device)\n","\n","                self.optimizer.zero_grad()\n","                outputs = self.model(images)\n","                loss = self.loss_function(outputs, y_true)\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n","                self.optimizer.step()\n","\n","                if (i+1) % 100 == 0:\n","                    print(\"Epoch %d Batch %d -- loss: %.3f\" % (epoch+1, i+1, loss))\n","\n","\n","    def test(self, on_train_set=False):\n","        holder = {}\n","        holder['y_true'], holder['y_hat'] = [], []\n","\n","        if on_train_set is True:\n","            print(\"Predicting on train set to get metrics\")\n","            dataloader = self.trainloader\n","        else:\n","            print(\"Predicting on eval set to get metrics\")\n","            dataloader = self.testloader\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            for data in dataloader:\n","                images, y_true = data\n","                images, y_true = images.to(self.device), y_true.to(self.device)\n","\n","                outputs = self.model(images)\n","                _, y_hat = torch.max(outputs, 1)   # logits not required, index pos is sufficient\n","                holder['y_true'].extend(\n","                    list(y_true.cpu().detach().numpy())\n","                )\n","                holder['y_hat'].extend(\n","                    list(y_hat.cpu().detach().numpy())\n","                )\n","\n","        y_true_all = holder['y_true']\n","        y_pred_all = holder['y_hat']\n","        M = confusion_matrix(y_true_all, y_pred_all)\n","        print(\"Confusion matrix: \\n\", M)\n","        print(classification_report(y_true_all, y_pred_all))"],"metadata":{"id":"NbL4mE1BM8wg"},"id":"NbL4mE1BM8wg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = DataManager()"],"metadata":{"id":"1F5fV9LLNAig"},"id":"1F5fV9LLNAig","execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier = Classifier(dataset)\n","classifier.train(lr=1e-4, epochs=1)"],"metadata":{"id":"BNL2wYOuNAyC"},"id":"BNL2wYOuNAyC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in classifier.model.named_parameters():\n","    print(name, param.shape, param.requires_grad)"],"metadata":{"collapsed":true,"id":"NVORtG5MDDf9"},"id":"NVORtG5MDDf9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier.test(on_train_set=True)"],"metadata":{"id":"f5YOmJDmNrLy"},"id":"f5YOmJDmNrLy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier.test(on_train_set=False)"],"metadata":{"id":"vG1cF1OtXOha"},"id":"vG1cF1OtXOha","execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier.model"],"metadata":{"collapsed":true,"id":"vUIKOolMRbJK"},"id":"vUIKOolMRbJK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_name = \"/content/drive/MyDrive/19-22Aug_Summer_Camp/model_21Aug.pt\"\n","torch.save(classifier.model.state_dict(), file_name)\n"],"metadata":{"id":"AkJhWzhKRK6V"},"id":"AkJhWzhKRK6V","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","file_name_2 = \"/content/drive/MyDrive/19-22Aug_Summer_Camp/model_2_21Aug.pkl\"\n","\n","with open(file_name_2, 'wb') as f:\n","    pickle.dump(classifier.model, f)"],"metadata":{"id":"8CvrpZLhXROQ"},"id":"8CvrpZLhXROQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","\n","last_layer_name, last_layer = list(new_model.named_modules())[-1]\n","featveclen = last_layer.weight.shape[1]\n","n_class = 10\n","exec(\"new_model.%s = nn.Linear(%s,%s)\" % \\\n","    (last_layer_name, featveclen, n_class)\n",")\n","new_model.load_state_dict(torch.load(file_name))"],"metadata":{"id":"dATn67HGRKw0"},"id":"dATn67HGRKw0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# del new_model\n","\n","# with open(file_name_2, 'rb') as f:\n","#     new_model = pickle.load(f)"],"metadata":{"id":"wXZNu-oJXnzP","executionInfo":{"status":"ok","timestamp":1723980236990,"user_tz":-480,"elapsed":8,"user":{"displayName":"James Koh","userId":"03873244289004905199"}}},"id":"wXZNu-oJXnzP","execution_count":1,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\n","    torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",")\n","new_model.to(device)\n","\n","holder = {}\n","holder['y_true'], holder['y_hat'] = [], []\n","\n","new_model.eval()\n","with torch.no_grad():\n","    for data in dataset.testloader:\n","        images, y_true = data\n","        images, y_true = images.to(device), y_true.to(device)\n","\n","        outputs = new_model(images)\n","        _, y_hat = torch.max(outputs, 1)   # logits not required, index pos is sufficient\n","        holder['y_true'].extend(\n","            list(y_true.cpu().detach().numpy())\n","        )\n","        holder['y_hat'].extend(\n","            list(y_hat.cpu().detach().numpy())\n","        )\n","\n","y_true_all = holder['y_true']\n","y_pred_all = holder['y_hat']\n","M = confusion_matrix(y_true_all, y_pred_all)\n","print(\"Confusion matrix: \\n\", M)\n","print(classification_report(y_true_all, y_pred_all))"],"metadata":{"id":"aT2J2yVETDil"},"id":"aT2J2yVETDil","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4lv8zrF1OEV9"},"id":"4lv8zrF1OEV9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First, remember to download 'Food5' folder and place it is your Google Drive\n","\n","!cp -r /content/drive/MyDrive/Data/Food5 /content/"],"metadata":{"id":"by8PumxW_dbQ"},"id":"by8PumxW_dbQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/"],"metadata":{"id":"CWgyTfGzQ5Uq"},"id":"CWgyTfGzQ5Uq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/Food5/"],"metadata":{"id":"VHnhbDWMOADY"},"id":"VHnhbDWMOADY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find /content/Food5/ -type f | wc -l"],"metadata":{"id":"gRiVkqpY1QDL"},"id":"gRiVkqpY1QDL","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"Gs_mtOmrh-Pw","metadata":{"id":"Gs_mtOmrh-Pw"},"outputs":[],"source":["root = \"/content/Food5\"\n","\n","class DataManager:\n","    def __init__(self, data_dir):\n","        self.C, self.H, self.W = 3, 224, 224\n","        self.batch_size = 8\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Resize(size=(self.H,self.W)),\n","            transforms.Normalize(mean, std)\n","        ])\n","        self.transform_ag = transforms.Compose([\n","            transforms.ColorJitter(\n","                brightness=0.10, contrast=0.10, saturation=0.10, hue=0.10\n","            ),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomVerticalFlip(p=0.5),\n","            transforms.RandomRotation(degrees=15),\n","            transforms.RandomResizedCrop(\n","                size=(self.H,self.W), scale=(0.90, 1.00), ratio=(0.90, 1.10)\n","            ),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","        self.trainset = torchvision.datasets.ImageFolder(\n","            os.path.join(data_dir,'train'),\n","            transform = self.transform_ag\n","        )\n","        self.testset = torchvision.datasets.ImageFolder(\n","            os.path.join(data_dir,'test'),\n","            transform=self.transform\n","        )\n","        self.class_to_idx = self.trainset.class_to_idx\n","        self.classes = list(self.class_to_idx.keys())\n","\n","        self.trainloader = torch.utils.data.DataLoader(\n","            self.trainset, batch_size=self.batch_size,\n","            shuffle=True, num_workers=0\n","        )\n","        self.testloader = torch.utils.data.DataLoader(\n","            self.testset, batch_size=self.batch_size,\n","            shuffle=False, num_workers=0\n","        )\n","\n","\n","    def show_sample_images(self):\n","        data = next(iter(self.trainloader))\n","        images_bchw, y_true = data\n","\n","        fig, axes = plt.subplots(2,2)\n","        images_bhwc = np.transpose(\n","            images_bchw.numpy(), (0,2,3,1)\n","        )\n","        axes[0,0].imshow(images_bhwc[0,])\n","        axes[0,0].set_title(\"%s\"%self.classes[y_true[0]])\n","        axes[0,1].imshow(images_bhwc[1,])\n","        axes[0,1].set_title(\"%s\"%self.classes[y_true[1]])\n","        axes[1,0].imshow(images_bhwc[2,])\n","        axes[1,0].set_title(\"%s\"%self.classes[y_true[2]])\n","        axes[1,1].imshow(images_bhwc[3,])\n","        axes[1,1].set_title(\"%s\"%self.classes[y_true[3]])\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","    def get_sample_model_input(self):\n","        data = next(iter(self.trainloader))\n","        images_bchw, y_true = data\n","\n","        return images_bchw, y_true"]},{"cell_type":"code","source":["data_dir = '/content/Food5'\n","\n","dataset = DataManager(data_dir)\n","dataset.show_sample_images()"],"metadata":{"id":"dkKvR0ORJ8bB"},"id":"dkKvR0ORJ8bB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["images_bchw, y_true = dataset.get_sample_model_input()\n","print(type(images_bchw), images_bchw.shape)\n","print(type(y_true), y_true.shape)"],"metadata":{"id":"BDremxwrJ9-g"},"id":"BDremxwrJ9-g","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"LjeODIBJXGfl","metadata":{"id":"LjeODIBJXGfl"},"outputs":[],"source":["class Classifier:\n","    def __init__(self, dataMananger, load_model=True):\n","        self.dataMananger = dataMananger\n","        self.trainloader = self.dataMananger.trainloader\n","        self.testloader = self.dataMananger.testloader\n","        self.classes = self.dataMananger.classes\n","        self.artifacts_dir = \"./artifact/\"\n","        if not os.path.exists(self.artifacts_dir):\n","            os.makedirs(self.artifacts_dir)\n","\n","        self.device = torch.device(\n","            torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n","        )\n","        print(\"Using device %s\" % self.device)\n","\n","        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","        self.replace_model_last_layer(len(self.classes))\n","\n","        if load_model is True:\n","            self.load_model()\n","\n","        self.model.to(self.device)\n","        self.create_loss_function()\n","\n","\n","    def create_loss_function(self):\n","        def custom_loss(y_pred_logits, y_true):\n","            \"\"\" Do what you want here, then return the loss \"\"\"\n","            loss = None\n","            return loss\n","\n","        # self.loss_function = custom_loss\n","        self.loss_function = nn.CrossEntropyLoss()\n","\n","\n","    def replace_model_last_layer(self, n_class):\n","        last_layer_name, last_layer = list(self.model.named_modules())[-1]\n","\n","        featveclen = last_layer.weight.shape[1]\n","        exec(\"self.model.%s = nn.Linear(%s,%s)\" % \\\n","            (last_layer_name, featveclen, n_class)\n","        )\n","\n","\n","    def save_model(self):\n","        if not os.path.exists(self.artifacts_dir+\"checkpoint/\"):\n","            os.makedirs(self.artifacts_dir+\"checkpoint/\")\n","\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        torch.save(\n","            self.model.state_dict(),\n","            self.artifacts_dir+\"checkpoint/model_%s.pt\" % timestamp\n","        )\n","        print(\"model_%s.pt successfully saved!\" % timestamp)\n","        return timestamp\n","\n","\n","    def load_model(self, filename=None):\n","        try:\n","            if filename is None:\n","                # get latest file, since files are named by date_time\n","                filename = sorted(\n","                    os.listdir(self.artifacts_dir+\"checkpoint/\")\n","                )[-1]\n","            self.model.load_state_dict(\n","                torch.load(\"%s/checkpoint/%s\" % (self.artifacts_dir, filename))\n","            )\n","            print(\"%s successfully loaded...\" % filename)\n","        except:\n","            print(\"Unable to load %s...\" % filename)\n","\n","\n","    def train(self, epochs=1, lr=1e-3, save=True):\n","        self.lr = lr\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n","        self.scheduler = \\\n","            lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, T_0=100, T_mult=1)\n","\n","        self.history = []\n","        print(\"Beginning training for %d epochs\" % epochs)\n","        print(\"lr: \", self.optimizer.param_groups[0]['lr'])\n","\n","        self.model.train()\n","        for epoch in range(epochs):\n","            print(\"Epoch %d\" % (epoch+1))\n","            for i, data in tqdm(enumerate(self.trainloader)):\n","                images, y_true = data\n","                images, y_true = images.to(self.device), y_true.to(self.device)\n","\n","                self.optimizer.zero_grad()\n","                outputs = self.model(images)\n","                loss = self.loss_function(outputs, y_true)\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n","                self.optimizer.step()\n","                self.scheduler.step()\n","\n","                if (i+1) % 10 == 0:\n","                    self.history.append(loss.item())\n","                    print(\"Epoch %d Batch %d -- loss: %.3f\" % (epoch+1, i+1, loss.item()))\n","\n","            if save is True:\n","                self.save_model()\n","\n","\n","    def test(self, on_train_set=False):\n","        holder = {}\n","        holder['y_true'] = []\n","        holder['y_hat'] = []\n","\n","        if on_train_set is True:\n","            print(\"Predicting on train set to get metrics\")\n","            dataloader = self.trainloader\n","        else:\n","            print(\"Predicting on eval set to get metrics\")\n","            dataloader = self.testloader\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            for data in dataloader:\n","                images, y_true = data\n","                images, y_true = images.to(self.device), y_true.to(self.device)\n","\n","                outputs = self.model(images)\n","                _, y_hat = torch.max(outputs, 1)   # logits not required, index pos is sufficient\n","                holder['y_true'].extend(\n","                    list(y_true.cpu().detach().numpy())\n","                )\n","                holder['y_hat'].extend(\n","                    list(y_hat.cpu().detach().numpy())\n","                )\n","\n","        y_true_all = holder['y_true']\n","        y_pred_all = holder['y_hat']\n","        M = confusion_matrix(y_true_all, y_pred_all)\n","        print(\"Confusion matrix: \\n\", M)\n","        print(classification_report(y_true_all, y_pred_all))"]},{"cell_type":"code","execution_count":null,"id":"3jOg4tnCVOZV","metadata":{"collapsed":true,"id":"3jOg4tnCVOZV"},"outputs":[],"source":["classifier = Classifier(\n","    dataset, load_model=False\n",")\n","\n","classifier.train(lr=1e-4, epochs=5)"]},{"cell_type":"code","execution_count":null,"id":"xiMwHUeMYNXa","metadata":{"id":"xiMwHUeMYNXa"},"outputs":[],"source":["classifier.test(on_train_set=True)"]},{"cell_type":"code","execution_count":null,"id":"7-F7DQXkZ0Oi","metadata":{"id":"7-F7DQXkZ0Oi"},"outputs":[],"source":["classifier.test(on_train_set=False)"]},{"cell_type":"code","execution_count":null,"id":"3N8-PalX0O13","metadata":{"id":"3N8-PalX0O13"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}